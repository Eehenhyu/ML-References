{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a reference for the areas of Machine Learning to include in the app.\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "## **Categories**\n",
    "There are two that all of the following fall into: Classification(Discovery) and Generation(Creativity)\n",
    "\n",
    "-There are pure classification problems which will be listed below, and there are neural network classification problems will will be number listed \n",
    "\n",
    "-Classification includes clustering if have data and no labels\n",
    " + K-means is really popular\n",
    " + Dimensionality reduction techniques like TSNE, Principle Component Analysis\n",
    " + Anomaly detection techniques\n",
    " + Most of these still use some type of supervised learning and some dont use backpropagation because of their simplicity\n",
    " + Multinomial Naive Bayes\n",
    "\n",
    "### 1. Supervised\n",
    "** Many implimentations for supervised can also be applied to other categories ** \n",
    "+ Feed Foward NN\n",
    "\n",
    "+ Convolutional NN\n",
    " - Learns mapping between input data and output label\n",
    " - Basically a series of matrix multiplications followed by a summation operation\n",
    " - Takes sections of pixel values and only takes the maximum value to use in the next operation/propagation(max pooling), this also speeds up training time\n",
    " - Can implement dropout to prevent overfitting of the data(regularization technique\n",
    " - Generally not good with rotational movement in images unless its trained on that\n",
    " - Usually the more layers the better, but up to a point\n",
    " \n",
    "+ Recurrent NN\n",
    "\n",
    "+ Generative Adverserial Network https://www.youtube.com/watch?v=PhCM3qoRZHE\n",
    "\n",
    "+ Capsule Network https://github.com/llSourcell/capsule_networks\n",
    " - This is like a CNN except instead of adding more layers, it nests a new layer inside the layers already present(capsule)\n",
    " - This makes the model more robust with roations or distortions of an image\n",
    " - Uses routing agreements between layers instead of max pooling\n",
    " ** Keep in mind this model has only been trained on MNIST so it might have a vanishing gradient problem on larger sets or something else might go wrong on them **\n",
    " \n",
    "+ Sentiment Analysis https://www.youtube.com/watch?v=AJVP96tAWxw\n",
    " - This is basically a classifier for natural langauge, more tuning is being done on this \n",
    "\n",
    "### 2. Semi-supervised\n",
    "\n",
    "### 3. Unsupervised Learning\n",
    "+ Hierarchical Temporal Memory (Numenta) https://www.youtube.com/watch?v=u-BIsnN-xxM\n",
    " * Learns from unlabeled data streams(trying to simulate a neocortex in humans)\n",
    " * Can learn from a few dozen examples instead of thousands and can be more reliable with one-shot learning(case specific)\n",
    " * Uses sparse data representations\n",
    " * Uses Hebbian learning(for self organizing maps)\n",
    " \n",
    "+ Autoencoders https://www.youtube.com/watch?v=H1AllrJ-_30\n",
    " - Great for dimensionality reduction and learning some features\n",
    " - Good for cases where given input and try to reconstruct it as output\n",
    " \n",
    "+ Differentiable Neural Computer\n",
    " - Very complex system that can relate different topics\n",
    " - Still uses backpropagation\n",
    "+ Self Organizing Maps\n",
    " - No Backpropagation used\n",
    " - All weights are random then the input node comes in and tries to find node closest to it then strengths the nodes around that one\n",
    " - Similar to clustering\n",
    " \n",
    "+ Baysien Learning\n",
    " - Gives an  advantage to the weight and possibly hyperparameter initialization\n",
    " - Simliar to how children can learn things quickly since they seemed to be primed for it\n",
    " \n",
    "### 4. Reinforcement Learning\n",
    "+ Evolutionary Strategies https://github.com/llSourcell/neuroevolution-for-flappy-birds \n",
    "https://www.youtube.com/watch?v=hVv68aHYSs4\n",
    " - Tries to mimick evolution by having functions like fitness and crossover selection, genetic algorithms, etc\n",
    " - Typically used in games\n",
    " - Have been shown to be effective for these kind of problems and even outperform traditional approaches in some domains\n",
    " - Does not use gradient descent, uses something similar to a structured random search\n",
    "+ Generally time based, mix or supervided and unsupervised https://www.youtube.com/watch?v=fRmZck1Dakc\n",
    " \n",
    "### 5. Future Possibilities\n",
    "+ Both HW and SW possibilities https://github.com/llSourcell/7_Research_Directions_Deep_Learning\n",
    "+ Inspirations from Neuroscience https://github.com/llSourcell/machine_learning_and_neuroscience\n",
    "\n",
    "### 6. Hardware\n",
    "+ Specific hardware is being built for ML applications: TPU's(instead of CPU or GPU) https://www.youtube.com/watch?v=jgNwywYcH4w\n",
    "+ Training in the Cloud easily https://www.youtube.com/watch?v=Bgwujw-yom8\n",
    "+ Neural Compure Stick(AI USB) https://www.youtube.com/watch?v=KuM67WfTXBQ\n",
    "+ Which hardware to pick/cloud options https://www.youtube.com/watch?v=dtFZrFKMiPI\n",
    "+ Azure Computing https://www.youtube.com/watch?v=LQEyK4POowk\n",
    "+ Google Cloud https://www.youtube.com/watch?v=tdhVXKf_WSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Languages\n",
    "\n",
    "- Tensorflow\n",
    " + Written in C++\n",
    " + Comes with Tensorboard, a data visualization tool https://www.youtube.com/watch?v=3bownM3L5zM\n",
    "\n",
    "- Keras(still most popular)\n",
    " + Very high level wrapper to use over Tensorflow, Theano, CNTK\n",
    " + Fastest options when need to quickly build and test a model built from standard layers\n",
    "\n",
    "- PyTorch (gaining popularity)\n",
    " + Pretty much just ported the Torch framework to Python\n",
    " + Uses Dynamic Computation Graphs(created on the fly)\n",
    " + Defined by run instead of define and run\n",
    " + Very useful when inputs vary(like unstructured data with text)\n",
    " + Fast for writting custom modules and debugging layers\n",
    " + Best for researchers\n",
    "\n",
    "- Theano \n",
    " + No longer maintained(as of 2018)\n",
    "\n",
    "- H2O.io\n",
    "\n",
    "- Caffe\n",
    "\n",
    "- AmazonMXNet https://github.com/llSourcell/MXNet\n",
    " + Good scaling like Tensorflow \n",
    " + Multilanguage support (scala, R, etc.)\n",
    " + Easily distrubited on the cloud, was meant to work with AWS\n",
    " + Best performing for very large data sets since GPU utilization is really good\n",
    " + Uses imperitive programming which is better for RNNs since its defined during runtime, but this also makes it harder to optimize\n",
    " + \n",
    " \n",
    "- Microsoft CNTK\n",
    "\n",
    "- ONNX open format to share deep learning models across frameworks\n",
    "\n",
    "- Googles autoML \n",
    " + Allows non-ML developers to develop custom CNNs to work with\n",
    "\n",
    "### For Mobile\n",
    "+ CoreML (iOS) https://github.com/llSourcell/A_guide_to_coreML\n",
    " - Frameworks before this were BNNS(Basic Neural Network Subroutines) which runs on the CPU and MPSCNN(Metal Performance Shader Convolutional Neural Network) which runs on the GPU\n",
    " ** Keep in mind for inference the CPU is SOMETIMES faster, have to check to make sure **\n",
    " - These previous frameworks and CoreML allow device to run inference(pre-trained model without needing internet connection), which means none of these frameworks will allow training\n",
    " - CoreML is built on top of the previous two and uses the CPU and GPU and is very easy to use since it abstracts so well\n",
    " - Has 3 APIs on top to use: Vision, Natural Language Processing, GameplayKit\n",
    " - Apple has a bunch of pretrained models ready to use or can use own\n",
    " - Able to convert a lot of models except ones from Tensorflow(will have to convert them yourself)\n",
    " \n",
    "+ Tensorflow (Andriod) https://github.com/llSourcell/A_Guide_to_Running_Tensorflow_Models_on_Android\n",
    " - No training on actual device, just inference\n",
    " - Has SDK(java based and standard library for apps) and NDK(c++ based just like Tensorflow)\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "There are multiple data set sizes and restrictions that come into play when thinking about what kind of algorithm to use on the data set: Size, Labeled/Unlabeled, Number of features/dimensions, bias/unbiased or skewed/nonskewed, clean/unclean, etc.\n",
    "\n",
    "Many of these steps can be broken down into:  Cleaning -> Transformation -> Reduction\n",
    "\n",
    "1. Get a dataset https://www.youtube.com/watch?v=0xVqLJe9_CY https://www.youtube.com/watch?v=koiTTim4M-s\n",
    "2. Data must be cleaned if possible https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure\n",
    "\n",
    "1. Input Layer: Weight Initialization + Bias(if needed)\n",
    "2. Hidden Layer: Activation Functions\n",
    "3. Output Layer: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization + Bias(if needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "** These are applied non-linearities so the NN can handle nonlinear functions **\n",
    "\n",
    "1. Sigmoid [shouldn't be used anymore]\n",
    " + Simple to implement but causes gradients to vanish\n",
    " + Output isn't zero-centered (starts at 0 and ends at 1 instead of starting at -1 and ending at 1) which makes optimazation     harder\n",
    " \n",
    "2. Tanh [shouldn't be used anymore]\n",
    " + Zero centered but still suffers from vanishing gradient problem\n",
    "\n",
    "3. ReLU(Rectified Linear Unit) [this is the standard to use]\n",
    " + Learns faster and avoids vanishing gradient problem\n",
    " + Not zero centered since everything below 0 just gets counted as 0 but linear with a slope of once when its greater than 0\n",
    " + Simple implementation so simpler computation\n",
    " + Problem with fragile units during training that die off, so a big gradient flowing through a ReLU neuron could cause a weight update that makes it never activate on any neuron again, so gradients flowing through will now always be zero\n",
    "\n",
    "4. Leaky ReLU [use if have vanishing gradient problem]\n",
    " + Like ReLU but instead of going to 0 if below zero, the neuron will have a small negative slope\n",
    "\n",
    "5. Maxout [maybe use if have lots of computation available]\n",
    " + Generalized form of ReLU and Leaky ReLU but doubles the number of parameters for each neuron so huge tradeoff!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation & Gradient Descent https://www.youtube.com/watch?v=q555kfIFUCM\n",
    "\n",
    "1. Softmax \n",
    " + Good for classification since it gives probabilities for different classes\n",
    "2. Linear \n",
    " + Good for regression since the signal goes through unchanged\n",
    " \n",
    "### Gradient Descent https://github.com/llSourcell/The_evolution_of_gradient_descent/\n",
    "- Traditionally computes gradient of the loss function with regards to the parameters for the entire training set for a given number of epochs \n",
    " + this is slow though since the whole computation is needed for a single update \n",
    " + its also hard to deal with for data sets that dont fit in memory\n",
    "- An improvement on this is Stochastic Gradient Descent\n",
    " + Perform a training update for each training example and label to calculate all of them\n",
    " + These more frequent updates have higher variance which causes bigger fluctuations which helps to find new and possibly better local minima\n",
    " + Also has a problem of overshooting since it complicates convergence to the global min\n",
    "- Minibatch Gradient Descent (most used method)\n",
    " + Takes the positives of both previous methods by performing an update for every subset of training examples that we can decide the size of\n",
    "- Momentum\n",
    " + Softens the oscillations of SGD and amplifies the speed of moving in the correct direction\n",
    " + Problem is the momentum could be too high when it reaches the minimum and end up passing it\n",
    "- Nestorov Momentum\n",
    " + Solves the problem of missing the minimum stated above\n",
    " \n",
    "** All of this may be applied to the learning rate aswell ** \n",
    "+ These perform well when data is sparse\n",
    "- Adagrad (adaptive gradient)\n",
    " + Allows learning rate to adapt based on the parameters\n",
    " + Makes big updates for infrequent params and small updates for frequent ones\n",
    " + Problem is that its learning rate is always decreasing to the point where it'll stop completely\n",
    "- Adadelta\n",
    " + Prevents the decaying learning rate from above\n",
    "- Adam (Adaptive Moment Estimation) [Best one to use and fastest in most cases]\n",
    " + Calculates the learning rates and momentum changes\n",
    " \n",
    "** Updated info for GD **\n",
    "- Synthetic Gradients https://github.com/llSourcell/synthetic_gradients_explained\n",
    " + Dont have to wait for a full forward and backward pass through the NN\n",
    " + Not the true gradient but an approximation to what the gradient would be\n",
    " + Faster way to optimize NN and allows decoupling of layers from having to wait for all the other layers\n",
    " + This is also its own 1 layer NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Code\n",
    "\n",
    "Add these examples of basic and more complex NNs running once the choice is made\n",
    "\n",
    "+ Sentiment Analysis https://www.youtube.com/watch?v=AJVP96tAWxw\n",
    "+ Flower Petal Classifier https://www.youtube.com/watch?v=2FOXR16mLow\n",
    "+ RNN w/LSTM Cell Music Composer https://www.youtube.com/watch?v=S_f2qV2_U00\n",
    "+ Deep Q Learning(a CNN) Game AI https://www.youtube.com/watch?v=HBAUeJkFMH0\n",
    "+ Amazons DSSTN Movie Recommender https://www.youtube.com/watch?v=eKmIVU8EUbw\n",
    "+ Style Transfer CNN https://www.youtube.com/watch?v=9Mxw_ilpvwA\n",
    "+ Chatbot https://www.youtube.com/watch?v=5_SAroSvC0E\n",
    "+ Googles Parsy for AI Reading https://www.youtube.com/watch?v=AKwfVAKaigI\n",
    "+ AI Writing with GRUs https://www.youtube.com/watch?v=x24VEUEph0Q\n",
    "+ api.ai Chatbot https://www.youtube.com/watch?v=c6R3EjMQ7H0\n",
    "+ One-shot leanring https://www.youtube.com/watch?v=FIjy3lV_KJU\n",
    "+ GAN example https://www.youtube.com/watch?v=deyOX6Mt_As\n",
    "+ IBM Tone Analysis https://www.youtube.com/watch?v=89FHXM2q36s\n",
    "+ Rap Lyric Generator https://www.youtube.com/watch?v=yE0dcDNRZjw\n",
    "+ Autoencoder https://www.youtube.com/watch?v=GWn7vD2Ud3M\n",
    "+ RC AI car https://www.youtube.com/watch?v=hBedCdzCoWM\n",
    "+ Virus Classifier https://www.youtube.com/watch?v=iLNHVwSu9EA\n",
    "+ Quick RNN https://www.youtube.com/watch?v=cdLUzrjnlr4\n",
    "+ Life Simulation https://www.youtube.com/watch?v=bNsrHRJQdKo\n",
    "+ General Image Classifier CNN https://www.youtube.com/watch?v=QfNvhPx5Px8\n",
    "+ Music Generation CNN https://www.youtube.com/watch?v=ZE7qWXX05T0\n",
    "+ Gender Classifier w/Sublime https://www.youtube.com/watch?v=T5pRlIbr6gg\n",
    "+ Twitter Sentiment Analysis https://www.youtube.com/watch?v=o_OZdbCzHUA\n",
    "+ Move Recommender https://www.youtube.com/watch?v=9gBC9R-msAk\n",
    "+ Deep Dream https://www.youtube.com/watch?v=MrBzgvUNr4w\n",
    "+ Gamma Ray Classification with Genetic Algorithm https://www.youtube.com/watch?v=dSofAXnnFrY\n",
    "+ Climate Data and change https://www.youtube.com/watch?v=9MvbNPQiEE8 (at end of video)\n",
    "+ Chatbot with TF https://www.youtube.com/watch?v=SJDEOWLHYVo\n",
    "+ Gamebot https://www.youtube.com/watch?v=mGYU5t8MO7s\n",
    "+ Speech Recognizer RNN https://www.youtube.com/watch?v=u9FPqkuoEJ8\n",
    "+ Gamebot with Q learning https://www.youtube.com/watch?v=A5eihauRQvo\n",
    "+ Regression https://www.youtube.com/watch?v=vOppzHpvTiQ\n",
    "+ Basic NN https://www.youtube.com/watch?v=p69khggr1Jo\n",
    "+ Sentiment Analysis https://www.youtube.com/watch?v=si8zZHkufRY\n",
    "+ Image Classification https://www.youtube.com/watch?v=cAICT4Al5Ow\n",
    "+ Transfer Art https://www.youtube.com/watch?v=Oex0eWoU7AQ\n",
    "+ Music Generation RNN w/LSTM https://www.youtube.com/watch?v=4DMm5Lhey1U\n",
    "+ Text Summerizer Seq-to-Seq w/Attention https://www.youtube.com/watch?v=ogrJaOIuBx4\n",
    "+ Language Translation https://www.youtube.com/watch?v=nRBnh4qbPHI\n",
    "+ Chatbot Q&A w/GRUs https://www.youtube.com/watch?v=t5qgjJIBy9g https://github.com/xkortex/Siraj_Chatbot_Challenge\n",
    "+ Slot Machine w/Policy Gradients https://www.youtube.com/watch?v=AIeWLTUYLZQ\n",
    "+ Image Generation w/Autoencoder https://www.youtube.com/watch?v=3-UDwk1U77s\n",
    "+ Video Generation w/GANs https://www.youtube.com/watch?v=-E2N1kQc8MM\n",
    "+ HardWare Smart Blinds https://www.youtube.com/watch?v=YKtbO6iW9-Y\n",
    "+ Image generation from Text w/GANs https://www.youtube.com/watch?v=gmvRStL_Dag\n",
    "+ One-shot Classification https://www.youtube.com/watch?v=tChcZpBbTTA&t=3s\n",
    "+ Monte Carlo Prediction https://www.youtube.com/watch?v=-YpalutQCKw\n",
    "+ Q learning https://www.youtube.com/watch?v=aCEvtRtNO-M\n",
    "+ Pong Policy Gradient https://www.youtube.com/watch?v=pN7ETkOizGM\n",
    "+ Music Generation Autoencoder https://www.youtube.com/watch?v=U9elzaxqpsg\n",
    "+ Actor Critic RL https://www.youtube.com/watch?v=w_3mmm0P0j8\n",
    "+ PPO Military Robots https://www.youtube.com/watch?v=tm5kQmjfZN8\n",
    "+ Unity 3D AI https://www.youtube.com/watch?v=bqsfkGbBU6k\n",
    "+ 3D Machine Vision https://www.youtube.com/watch?v=EMjPqgLX14A\n",
    "+ Deepfakes https://www.youtube.com/watch?v=7XchCsYtYMQ\n",
    "+ Calculus Q&A Bot example https://www.youtube.com/watch?v=HhqhFbwiaig\n",
    "+ Medical Image Classification https://www.youtube.com/watch?v=DCcmFXXAHf4\n",
    "+ Image Recognition using Tensorflow.js https://www.youtube.com/watch?v=Nc8kZABv-KE\n",
    "+ Chatbot Updated https://www.youtube.com/watch?v=PXJtFc8DjsE\n",
    "+ Resume AI https://www.youtube.com/watch?v=p3SKx5C04qg\n",
    "+ Self Driving Car Sim https://www.youtube.com/watch?v=yt015gM-ync\n",
    "+ World Modeling for games https://www.youtube.com/watch?v=IZPKohYNri4\n",
    "+ DeepMind's Fast RL https://www.youtube.com/watch?v=N0Ld2iTMaMs\n",
    "+ AWS Sentiment Analysis https://www.youtube.com/watch?v=zkzED9HvMG0\n",
    "+ Binary Sentiment Analysis https://www.youtube.com/watch?v=H6ii7NFdDeg\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
